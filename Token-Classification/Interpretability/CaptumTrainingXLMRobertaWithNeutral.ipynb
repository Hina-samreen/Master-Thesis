{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "env: CUDA_VISIBLE_DEVICES=0\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "%env CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install captum\n",
    "%pip install torchtext==0.8.1\n",
    "%pip install transformers\n",
    "%pip install SentencePiece\n",
    "%pip install underthesea\n",
    "%pip install nltk\n",
    "%pip install protobuf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "#from underthesea import word_tokenize, sent_tokenize, text_normalize\n",
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from captum.attr import  LayerIntegratedGradients, visualization as viz, LayerConductance\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "#import seaborn as sns\n",
    "\n",
    "\n",
    "class Colors:\n",
    "    HEADER = '\\033[95m'\n",
    "    OKBLUE = '\\033[94m'\n",
    "    OKCYAN = '\\033[96m'\n",
    "    OKGREEN = '\\033[92m'\n",
    "    WARNING = '\\033[93m'\n",
    "    FAIL = '\\033[91m'\n",
    "    ENDC = '\\033[0m'\n",
    "    BOLD = '\\033[1m'\n",
    "    UNDERLINE = '\\033[4m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>instance_id</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>negative object_spans</th>\n",
       "      <th>negative spans</th>\n",
       "      <th>positive spans</th>\n",
       "      <th>positive object_spans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ekaterini@gmail.com</td>\n",
       "      <td>898</td>\n",
       "      <td>Nur Politiker wollen Krieg ! Was wenn keiner m...</td>\n",
       "      <td>negative</td>\n",
       "      <td>['Politiker ', 'Krieg ']</td>\n",
       "      <td>['Was wenn keiner mehr Bock hat', 'zu sterben'...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ekaterini@gmail.com</td>\n",
       "      <td>833</td>\n",
       "      <td>Der Klimawandel ist ein völlig normaler Prozes...</td>\n",
       "      <td>positive</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>völlig normaler Prozess</td>\n",
       "      <td>Klimawandel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ekaterini@gmail.com</td>\n",
       "      <td>1428</td>\n",
       "      <td>Man will die Stadthalle für einen #Bürgerdialo...</td>\n",
       "      <td>negative</td>\n",
       "      <td>Demokraten</td>\n",
       "      <td>['missliebige Partei ', 'Was denken die']</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ekaterini@gmail.com</td>\n",
       "      <td>431</td>\n",
       "      <td>Besonders beliebt ist auch \"Wir mussten währen...</td>\n",
       "      <td>negative</td>\n",
       "      <td>Corona</td>\n",
       "      <td>die während Corona auch gern auf die Maske ver...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ekaterini@gmail.com</td>\n",
       "      <td>1315</td>\n",
       "      <td>Die USA sollten sich mäßigen Israel zu ermahne...</td>\n",
       "      <td>positive</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>handelt moralisch richtig</td>\n",
       "      <td>['Israel ', 'Israel ']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>ekaterini@gmail.com</td>\n",
       "      <td>1134</td>\n",
       "      <td>Auch Israel begeht Kriegsverbrechen an der Ziv...</td>\n",
       "      <td>negative</td>\n",
       "      <td>Israel</td>\n",
       "      <td>['begeht Kriegsverbrechen', 'aber Kritik an Is...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>ekaterini@gmail.com</td>\n",
       "      <td>127</td>\n",
       "      <td>Sogenannte Zivilisten? geht's noch?</td>\n",
       "      <td>negative</td>\n",
       "      <td>...</td>\n",
       "      <td>geht's noch?</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>ekaterini@gmail.com</td>\n",
       "      <td>366</td>\n",
       "      <td>Ganz normal, dass wir in Zeiten der Klimakrise...</td>\n",
       "      <td>negative</td>\n",
       "      <td>Klimakrise</td>\n",
       "      <td>['hypokapitalistischen', 'Nice one, Humanity',...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>ekaterini@gmail.com</td>\n",
       "      <td>473</td>\n",
       "      <td>Kleine Nachhilfe: Ein paar hunderttausend Grün...</td>\n",
       "      <td>negative</td>\n",
       "      <td>Grüne</td>\n",
       "      <td>eine Klatsche bekommen habt</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>ekaterini@gmail.com</td>\n",
       "      <td>125</td>\n",
       "      <td>Hamas wird wie immer die Feuerpause brechen. D...</td>\n",
       "      <td>negative</td>\n",
       "      <td>Hamas</td>\n",
       "      <td>['Feuerpause brechen', 'Die wollen keinen Frie...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    user  instance_id  \\\n",
       "0    ekaterini@gmail.com          898   \n",
       "1    ekaterini@gmail.com          833   \n",
       "2    ekaterini@gmail.com         1428   \n",
       "3    ekaterini@gmail.com          431   \n",
       "4    ekaterini@gmail.com         1315   \n",
       "..                   ...          ...   \n",
       "295  ekaterini@gmail.com         1134   \n",
       "296  ekaterini@gmail.com          127   \n",
       "297  ekaterini@gmail.com          366   \n",
       "298  ekaterini@gmail.com          473   \n",
       "299  ekaterini@gmail.com          125   \n",
       "\n",
       "                                                  text sentiment  \\\n",
       "0    Nur Politiker wollen Krieg ! Was wenn keiner m...  negative   \n",
       "1    Der Klimawandel ist ein völlig normaler Prozes...  positive   \n",
       "2    Man will die Stadthalle für einen #Bürgerdialo...  negative   \n",
       "3    Besonders beliebt ist auch \"Wir mussten währen...  negative   \n",
       "4    Die USA sollten sich mäßigen Israel zu ermahne...  positive   \n",
       "..                                                 ...       ...   \n",
       "295  Auch Israel begeht Kriegsverbrechen an der Ziv...  negative   \n",
       "296                Sogenannte Zivilisten? geht's noch?  negative   \n",
       "297  Ganz normal, dass wir in Zeiten der Klimakrise...  negative   \n",
       "298  Kleine Nachhilfe: Ein paar hunderttausend Grün...  negative   \n",
       "299  Hamas wird wie immer die Feuerpause brechen. D...  negative   \n",
       "\n",
       "        negative object_spans  \\\n",
       "0    ['Politiker ', 'Krieg ']   \n",
       "1                         ...   \n",
       "2                  Demokraten   \n",
       "3                     Corona    \n",
       "4                         ...   \n",
       "..                        ...   \n",
       "295                    Israel   \n",
       "296                       ...   \n",
       "297                Klimakrise   \n",
       "298                    Grüne    \n",
       "299                    Hamas    \n",
       "\n",
       "                                        negative spans  \\\n",
       "0    ['Was wenn keiner mehr Bock hat', 'zu sterben'...   \n",
       "1                                                  ...   \n",
       "2            ['missliebige Partei ', 'Was denken die']   \n",
       "3    die während Corona auch gern auf die Maske ver...   \n",
       "4                                                  ...   \n",
       "..                                                 ...   \n",
       "295  ['begeht Kriegsverbrechen', 'aber Kritik an Is...   \n",
       "296                                       geht's noch?   \n",
       "297  ['hypokapitalistischen', 'Nice one, Humanity',...   \n",
       "298                        eine Klatsche bekommen habt   \n",
       "299  ['Feuerpause brechen', 'Die wollen keinen Frie...   \n",
       "\n",
       "                positive spans   positive object_spans  \n",
       "0                          ...                     ...  \n",
       "1      völlig normaler Prozess             Klimawandel  \n",
       "2                          ...                     ...  \n",
       "3                          ...                     ...  \n",
       "4    handelt moralisch richtig  ['Israel ', 'Israel ']  \n",
       "..                         ...                     ...  \n",
       "295                        ...                     ...  \n",
       "296                        ...                     ...  \n",
       "297                        ...                     ...  \n",
       "298                        ...                     ...  \n",
       "299                        ...                     ...  \n",
       "\n",
       "[300 rows x 8 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('test_subset.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"Hina541/fine-tuned-xlm_roberta-german-WithNeutral\"\n",
    "\n",
    "# load model from your desired model path\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "model.to(device)\n",
    "model.eval()\n",
    "model.zero_grad()\n",
    "\n",
    "# load tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('cardiffnlp/twitter-xlm-roberta-base-sentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'negative': 0, 'neutral': 1, 'positive': 2}\n",
      "{0: 'negative', 1: 'neutral', 2: 'positive'}\n"
     ]
    }
   ],
   "source": [
    "id2label = model.config.id2label\n",
    "label2id = model.config.label2id\n",
    "print(label2id)\n",
    "print(id2label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>instance_id</th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>negative object_spans</th>\n",
       "      <th>negative spans</th>\n",
       "      <th>positive spans</th>\n",
       "      <th>positive object_spans</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>ekaterini@gmail.com</td>\n",
       "      <td>389</td>\n",
       "      <td>Wieviele wurden von ihrem Arzt nach Hause gesc...</td>\n",
       "      <td>negative</td>\n",
       "      <td>['Long Covid', 'Impfschäden']</td>\n",
       "      <td>['Wieviele wurden von ihrem Arzt nach Hause ge...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>ekaterini@gmail.com</td>\n",
       "      <td>594</td>\n",
       "      <td>Das Erzeugen von \"Klimaangst\" ist die elegante...</td>\n",
       "      <td>negative</td>\n",
       "      <td>Klimaangst</td>\n",
       "      <td>elegante Variante des Kindesmissbrauchs.</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>ekaterini@gmail.com</td>\n",
       "      <td>1431</td>\n",
       "      <td>Ich hab nachgedacht über die enorme Häufing vo...</td>\n",
       "      <td>negative</td>\n",
       "      <td>Impfschäden</td>\n",
       "      <td>['ziemlicher Müll', 'es gibt richtig viele dum...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    user  instance_id  \\\n",
       "200  ekaterini@gmail.com          389   \n",
       "282  ekaterini@gmail.com          594   \n",
       "51   ekaterini@gmail.com         1431   \n",
       "\n",
       "                                                  text sentiment  \\\n",
       "200  Wieviele wurden von ihrem Arzt nach Hause gesc...  negative   \n",
       "282  Das Erzeugen von \"Klimaangst\" ist die elegante...  negative   \n",
       "51   Ich hab nachgedacht über die enorme Häufing vo...  negative   \n",
       "\n",
       "             negative object_spans  \\\n",
       "200  ['Long Covid', 'Impfschäden']   \n",
       "282                     Klimaangst   \n",
       "51                     Impfschäden   \n",
       "\n",
       "                                        negative spans positive spans  \\\n",
       "200  ['Wieviele wurden von ihrem Arzt nach Hause ge...            ...   \n",
       "282           elegante Variante des Kindesmissbrauchs.            ...   \n",
       "51   ['ziemlicher Müll', 'es gibt richtig viele dum...            ...   \n",
       "\n",
       "    positive object_spans  label  \n",
       "200                   ...      0  \n",
       "282                   ...      0  \n",
       "51                    ...      0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'] = df['sentiment'].map(label2id)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting attributions for each word from captum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class XAI:\n",
    "    def __init__(self, text_, label_, tokenizer_, model_, device_):\n",
    "        self.text = text_\n",
    "        self.label = label_\n",
    "        self.tokenizer = tokenizer_\n",
    "        self.model = model_\n",
    "        self.ref_token_id = self.tokenizer.pad_token_id\n",
    "        self.sep_token_id = self.tokenizer.sep_token_id\n",
    "        self.cls_token_id = self.tokenizer.cls_token_id\n",
    "        self.device = device_\n",
    "        self.input_ids = None\n",
    "        self.ref_input_ids = None\n",
    "\n",
    "    def construct_input_ref(self):\n",
    "        text_ids = self.tokenizer.encode(self.text, add_special_tokens=False)\n",
    "        input_ids = [self.cls_token_id] + text_ids + [self.sep_token_id]\n",
    "        ref_input_ids = [self.cls_token_id] + [self.ref_token_id] * len(text_ids) + [self.sep_token_id]\n",
    "\n",
    "        self.input_ids = torch.tensor([input_ids], device=device)\n",
    "        self.ref_input_ids = torch.tensor([ref_input_ids], device=device)\n",
    "\n",
    "        return self.input_ids, self.ref_input_ids\n",
    "\n",
    "    def custom_forward(self, inputs):\n",
    "        return torch.softmax(self.model(inputs)[0], dim=1)[0]  # multi-class\n",
    "        #return torch.sigmoid(self.model(inputs)[0])[0]  # binary\n",
    "\n",
    "    def visualize(self):\n",
    "        self.input_ids, self.ref_input_ids = self.construct_input_ref()\n",
    "        self.all_tokens = tokenizer.convert_ids_to_tokens(self.input_ids[0])\n",
    "\n",
    "        lig = LayerIntegratedGradients(self.custom_forward, self.model.roberta.embeddings)\n",
    "        attributions, delta = lig.attribute(inputs=self.input_ids,\n",
    "                                            baselines=self.ref_input_ids,\n",
    "                                            n_steps=500,\n",
    "                                            internal_batch_size=3,\n",
    "                                            return_convergence_delta=True)\n",
    "\n",
    "        attributions = attributions.sum(dim=-1).squeeze()\n",
    "        attributions_sum = attributions / torch.norm(attributions)\n",
    "\n",
    "        score_bert = self.custom_forward(self.input_ids)\n",
    "        prod_pred = score_bert.max()\n",
    "        class_pred = score_bert.argmax()\n",
    "\n",
    "        print(f'{Colors.OKCYAN}Text:{Colors.ENDC} {self.text} \\n'\n",
    "              f'{Colors.OKCYAN}Predicted Probability:{Colors.ENDC} {prod_pred:,.2f}\\n'\n",
    "              f'{Colors.OKCYAN}Predicted Class:{Colors.ENDC} {class_pred} '\n",
    "              f'({id2label[class_pred.item()]}) vs. True Class: {self.label} ({id2label[self.label]})')\n",
    "\n",
    "        score_vis = viz.VisualizationDataRecord(attributions_sum,\n",
    "                                                pred_prob=prod_pred,\n",
    "                                                pred_class=class_pred,\n",
    "                                                true_class=self.label,\n",
    "                                                attr_class=class_pred,\n",
    "                                                attr_score=attributions_sum.sum(),\n",
    "                                                raw_input_ids=self.all_tokens,\n",
    "                                                convergence_score=delta)\n",
    "\n",
    "        viz.visualize_text([score_vis])\n",
    "        return attributions_sum\n",
    "\n",
    "        \n",
    "    def get_topk_attributed_tokens(self, attrs, k=5):\n",
    "        if len(attrs) <=5 :\n",
    "            values = torch.topk(attrs, k)\n",
    "        else:\n",
    "            values = torch.topk(attrs,len(attrs))\n",
    "        values,indices = [t.cpu().numpy() for t in values]\n",
    "        top_tokens = [self.all_tokens[idx] for idx in indices]\n",
    "        words =[]\n",
    "        only_words=[]\n",
    "        \n",
    "        encoded = tokenizer(self.text,padding=True,truncation=True,return_tensors=\"pt\")\n",
    "        word_ids = encoded.word_ids()\n",
    "        input_ids = encoded[\"input_ids\"].tolist()[0]\n",
    "        for word_id in sorted(set(word_ids) - {None}):\n",
    "            token_ids = [input_ids[i] for i in range(len(input_ids)) if word_ids[i]==word_id]\n",
    "            word = tokenizer.decode(token_ids,clean_up_tokenization_spaces=True).strip()\n",
    "            position_ids_token = np.where(np.array(encoded.word_ids())==word_id)\n",
    "            #print('position ids',list(position_ids_token))\n",
    "            attributions_grouped = []\n",
    "            indices_grouped = []\n",
    "            for position_id in position_ids_token:\n",
    "                #print(len(position_id))\n",
    "                if len(position_id) > 1:\n",
    "                    for i in range(len(position_id)):\n",
    "                        indices_index = list(indices).index(position_id[i])\n",
    "                        indices_grouped.append(indices_index)\n",
    "                        attributions_grouped.append(list(values)[indices_index])\n",
    "                else:\n",
    "                    indices_index = list(indices).index(position_ids_token)\n",
    "                    indices_grouped.append(indices_index)\n",
    "                    attributions_grouped.append(list(values)[indices_index])\n",
    "            words.append({\"word\":word,'attributions':attributions_grouped,'indices':indices_grouped})\n",
    "        only_words.append(word)\n",
    "        print(words)\n",
    "        return pd.DataFrame({'Word': top_tokens, 'Index': indices, 'Attribution': values}),words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calling the XAI function and saving the results to a file, the attributions and each word are saved as column 'Words'\n",
    "results = []\n",
    "for index, row in df.iterrows():\n",
    "    text = row['text']\n",
    "    label = df['label'].values[index]\n",
    "    negative_spans = row['negative spans']\n",
    "    negative_object_spans = row['negative object_spans']\n",
    "    positive_spans = row['positive spans']\n",
    "    positive_object_spans = row['positive object_spans']\n",
    "    xai = XAI(text, label, tokenizer, model, device)\n",
    "    attrs = xai.visualize()\n",
    "    topk_df,words = xai.get_topk_attributed_tokens(attrs, k=5)\n",
    "    score_bert = xai.custom_forward(xai.input_ids)\n",
    "    prod_pred = score_bert.max()\n",
    "    class_pred = score_bert.argmax()\n",
    "    result = {'Text': text, 'Actual Label': label, 'Predicted Label': class_pred.item(), 'Words':words, 'negative_object_spans':negative_object_spans, 'negative_spans':negative_spans, 'positive_object_spans':positive_object_spans,'positive_spans':positive_spans}\n",
    "    results.append(result)\n",
    "    #print(results)\n",
    "# create a new dataframe with the results\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df.to_csv('results_test_subset_fine-tuned-xlm_roberta-german-Test.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
